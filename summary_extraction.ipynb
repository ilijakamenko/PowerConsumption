{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f73a38f-ba23-4e3c-9ff9-d64195e79da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imdb import IMDBDataset\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eeca5e-a0c5-409c-9cca-e62d583d5f24",
   "metadata": {},
   "source": [
    "# Points of interest\n",
    "\n",
    "- energy / synapse (fJ) (energy / param)\n",
    "- energy / input vector (Î¼J)\n",
    "- Power (W)\n",
    "- Throughput (vectors / s)\n",
    "- Power / synapse (nW) (power / param)\n",
    "- Synapses (params)\n",
    "- Dataset size\n",
    "- Training time (s)\n",
    "- Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fb03089-3a64-46fd-a1f4-7521d832d39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset = IMDBDataset()\n",
    "imdb_size = len(imdb_dataset)\n",
    "imdb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f77a962-a31d-4e30-a15c-68507c9516f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_size = 60000\n",
    "imdb_size = 25000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9b41ea-1ca9-42ea-a682-97bcd0036e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmark_df(filename, batch_size = 64):\n",
    "    df = pd.read_csv(filename)\n",
    "    num_params = df.total_params.iloc[0]\n",
    "    df = df.sort_values(by=[\"run\", \"epoch\", \"elapsed_time\"])\n",
    "    df[\"iteration_time\"] = (\n",
    "        df.groupby([\"run\", \"epoch\"])[\"elapsed_time\"].diff().fillna(0)\n",
    "    )\n",
    "    iteration_energy = np.clip(df[\"power_consumption\"] * df[\"iteration_time\"], 0, None)\n",
    "    df[\"energy_J\"] = iteration_energy\n",
    "    energy_per_vector = iteration_energy / batch_size\n",
    "    df[\"energy_per_vector_uJ\"] = energy_per_vector * 10e6\n",
    "    df[\"energy_per_param_fJ\"] = energy_per_vector / num_params * 10e15\n",
    "    df[\"power_per_param_nW\"] = df[\"power_consumption\"] / (batch_size * num_params) * 10e9\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_summary_df(filename, dataset_size, batch_size=64, summarize=True):\n",
    "    df = load_benchmark_df(filename, batch_size)\n",
    "    results = []\n",
    "    run_groups = df.groupby([\"run\"])\n",
    "    for (run,), run_df in run_groups:\n",
    "        epoch_group = run_df.groupby([\"epoch\"])\n",
    "        train_duration = epoch_group[\"elapsed_time\"].max().sum()\n",
    "        epochs = len(epoch_group)\n",
    "        \n",
    "        mean_power = run_df[\"power_consumption\"].mean()\n",
    "        mean_energy_per_param = run_df[\"energy_per_param_fJ\"].mean()\n",
    "        mean_energy_per_vector = run_df[\"energy_per_vector_uJ\"].mean()\n",
    "        power_per_param = run_df[\"power_per_param_nW\"].mean()\n",
    "        run_energy = run_df[\"energy_J\"].sum()\n",
    "        params = run_df.total_params.iloc[0]\n",
    "        iterations = len(run_df)\n",
    "\n",
    "        energy_per_param_std = run_df[\"energy_per_param_fJ\"].std()\n",
    "        \n",
    "        results.append({\n",
    "            \"run\": run,\n",
    "            \"energy_per_param_fJ\": mean_energy_per_param,\n",
    "            \"energy_per_vector_uJ\": mean_energy_per_vector,\n",
    "            \"power_W\": mean_power,\n",
    "            \"energy_per_param_std\": energy_per_param_std,\n",
    "            \n",
    "            \"train_duration_s\": train_duration,\n",
    "            \"epochs\": epochs,\n",
    "            \"params\": params,\n",
    "            \"power_per_param_nW\": power_per_param,\n",
    "            \"energy_J\": run_energy,\n",
    "            \"iterations\": iterations,\n",
    "        })\n",
    "\n",
    "    energy_per_param = [g.values for name, g in run_groups[\"energy_per_param_fJ\"]]\n",
    "    f_statistic, p_value = f_oneway(*energy_per_param)\n",
    "        \n",
    "    runs_df = pd.DataFrame(results)\n",
    "\n",
    "    runs_df[\"dataset_size\"] = dataset_size\n",
    "    runs_df[\"throughput\"] = dataset_size * runs_df.epochs.iloc[0] / runs_df[\"train_duration_s\"]\n",
    "    stddev = runs_df[\"energy_per_param_fJ\"]\n",
    "\n",
    "    if not summarize:\n",
    "        return runs_df\n",
    "\n",
    "    summary_df = pd.DataFrame([runs_df.drop(columns=[\"run\"]).mean()])\n",
    "    summary_df[\"runs_std\"] = stddev\n",
    "    summary_df[\"f_stat\"] = f_statistic\n",
    "    summary_df[\"p_val\"] = p_value\n",
    "\n",
    "    reordered_cols = [\"energy_per_param_fJ\", \"energy_per_vector_uJ\", \"power_W\", \"throughput\", \"power_per_param_nW\", \"params\", \"dataset_size\", \"train_duration_s\", \"epochs\", \"energy_per_param_std\", \"iterations\", \"energy_J\", \"runs_std\", \"f_stat\", \"p_val\"]\n",
    "    summary_df = summary_df[reordered_cols]\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39dbb6-1e75-4335-ba7e-7ffe8551ab56",
   "metadata": {},
   "source": [
    "# Summarize final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2175e27e-bd48-4ab1-878e-4e25a7ae4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"lstm\", \"resnet18\", \"transformer\"]\n",
    "# platforms = [\"cuda_a100\", \"cuda\", \"npu\"]\n",
    "platforms = [\"cuda\"]\n",
    "dataset_sizes = {\n",
    "    \"lstm\": imdb_size,\n",
    "    \"transformer\": imdb_size,\n",
    "    \"resnet18\": mnist_size\n",
    "}\n",
    "platform_names = {\n",
    "    \"cuda_a100\": \"A100\",\n",
    "    \"cuda\": \"4060\",\n",
    "    \"npu\": \"NPU\",\n",
    "}\n",
    "\n",
    "metrics_map = {\n",
    "    \"energy_per_param_fJ\": \"Energy per synaptic event fJ\",\n",
    "    \"energy_per_vector_uJ\": \"Energy per input vector uJ\",\n",
    "    \"power_W\": \"Power W\",\n",
    "    \"throughput\": \"Throughput vectors/second\",\n",
    "    \"power_per_param_nW\": \"Power per synapse nW\",\n",
    "    \"params\": \"Number of synapses\",\n",
    "    \"dataset_size\": \"Dataset size\",\n",
    "    \"train_duration_s\": \"Traning duration sec\",\n",
    "    \"epochs\": \"Number of epochs\",\n",
    "    \"runs_std\": \"Standard Deviation\",\n",
    "    \"f_stat\": \"F-statistic\",\n",
    "    \"p_val\": \"P-value\",\n",
    "}\n",
    "cols_to_keep = [\n",
    "    'energy_per_param_fJ',\n",
    "    'energy_per_vector_uJ',\n",
    "    'power_W',\n",
    "    'throughput',\n",
    "    'power_per_param_nW',\n",
    "    'params',\n",
    "    'dataset_size',\n",
    "    'train_duration_s',\n",
    "    'epochs',\n",
    "    'runs_std',\n",
    "    'f_stat',\n",
    "    'p_val'\n",
    "]\n",
    "\n",
    "benchmark_filename = f\"benchmarks/{models[0]}_benchmark_{platforms[0]}.csv\"\n",
    "dataset_size = dataset_sizes[models[0]]\n",
    "df = get_summary_df(filename, dataset_size)[cols_to_keep]\n",
    "results_df = pd.DataFrame(index=df.T.index)\n",
    "runs = {}\n",
    "for platform in platforms:\n",
    "    for model in models:\n",
    "        benchmark_filename = f\"benchmarks/{model}_benchmark_{platform}.csv\"\n",
    "        dataset_size = dataset_sizes[model]\n",
    "        experiment_name = f\"{model.upper()}_{platform_names[platform]}\"\n",
    "        \n",
    "        runs_df = get_summary_df(benchmark_filename, dataset_size, summarize=False)\n",
    "        runs[experiment_name] = runs_df\n",
    "\n",
    "        summary_df = get_summary_df(benchmark_filename, dataset_size)[cols_to_keep]\n",
    "        results_df[experiment_name] = summary_df.T\n",
    "\n",
    "results_df.rename(index=metrics_map, inplace=True)\n",
    "results_df.index.name = \"NN Architecture\"\n",
    "with pd.ExcelWriter(\"results.xlsx\") as writer:\n",
    "    results_df.to_excel(writer, sheet_name=\"Summary\")\n",
    "    for run in runs:\n",
    "        runs[run].to_excel(writer, sheet_name=run, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
